# 模型评估与分析工作计划

## 一、目标

根据项目最终要求，对仓库中已有的各分割模型进行全面、系统的性能评估。本计划旨在确保评估过程的规范性、可复现性，并为最终的研究报告提供坚实的数据支持和清晰的可视化结果。

## 二、工作阶段与任务分解

### 第一阶段：定量评估脚本开发

1.  **创建核心评估脚本 (`src/evaluate.py`):**
    *   **目的:** 实现一个统一的、自动化的评估流程。
    *   **功能:**
        *   自动扫描并加载 `models/` 目录下的所有已训练模型 (`.pth` 文件)。
        *   根据模型文件名动态导入并实例化 `src/models_zoo/` 中对应的模型类。
        *   加载 `processed_data/test` 目录下的测试数据集。
        *   在`eval`模式下对测试集中的每一张图像进行预测。
        *   计算并累加每个预测结果的各项性能指标。
        *   输出每个模型的平均指标。

2.  **关键性能指标实现:**
    *   **区域重叠指标 (Region-based):**
        *   Dice Similarity Coefficient (DSC)
        *   Intersection over Union (IoU / Jaccard Index)
    *   **分类性能指标 (Classification-based):**
        *   Precision (精确率)
        *   Recall (召回率 / 灵敏度)
    *   **边界距离指标 (Boundary-based):**
        *   Hausdorff Distance (95th percentile, 95HD)
        *   Average Surface Distance (ASD)

3.  **结果输出与留痕:**
    *   **控制台输出:** 脚本执行完毕后，在控制台以格式化的表格形式打印各模型的核心性能指标，便于快速审查。
    *   **CSV文件保存:** 将详细的评估结果（每个模型、每个指标）保存到项目根目录下的 `evaluation_results.csv` 文件中。该文件将作为后续分析和制图的原始数据源。

### 第二阶段：训练过程可视化

1.  **创建可视化脚本 (`src/visualize_training.py`):**
    *   **目的:** 生成训练过程中的关键性能曲线图。
    *   **功能:**
        *   读取各模型训练时保存的日志文件（需先确认日志格式和位置）。
        *   绘制并保存以下曲线图：
            *   训练集 vs. 验证集 的损失函数（Loss）变化曲线。
            *   训练集 vs. 验证集 的准确率/Dice系数变化曲线。
    *   **输出:** 生成的图表将统一保存在一个新的 `output/` 目录下，并以模型名称命名，方便查阅。

### 第三阶段：文档与报告更新

1.  **更新 `docs/work.md`:**
    *   将 `evaluation_results.csv` 中的数据整理成Markdown表格，更新到文档中，形成“模型性能对比”章节。
    *   将 `output/` 目录下的训练曲线图嵌入文档，并附上简要的分析（例如，模型是否平稳收敛、是否存在过拟合现象等）。

2.  **更新 `README.md`:**
    *   在主 `README.md` 文件中新增“模型性能”章节，展示最终的性能对比表格，并提供指向 `docs/work.md` 的链接，供读者查阅详细的评估过程和分析。

## 四、执行流程

我将严格按照上述三个阶段顺序执行。首先从第一阶段的 `src/evaluate.py` 脚本编写开始。在编码前，我会先检查 `src/models_zoo` 和 `models` 目录的结构，并阅读一个训练脚本（如 `train.py`）以理解数据加载和模型实例化的具体方式。
